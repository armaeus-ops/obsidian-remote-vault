---
tags:
  - LF8
link: https://ilias.bs-technik-rostock.de:7777/ilias.php?ref_id=44914&cmd=view&cmdClass=ilobjlearningsequencelearnergui&cmdNode=7h%3A12a%3A126&baseClass=ilRepositoryGUI&lsocmd=layout&lsov=0
---

Es gibt mehrere Gründe, Datenquellen zusammenzuführen, die sowohl technische als auch wirtschaftliche Vorteile bieten. Hier sind einige der wichtigsten Gründe:

1. Ganzheitliche Sicht auf Daten

- Durch die Zusammenführung verschiedener Datenquellen kann ein vollständiger Überblick über das Unternehmen, die Kunden oder die Prozesse erreicht werden. Dies ermöglicht fundierte und umfassende Entscheidungen, die alle relevanten Informationen berücksichtigen.
- Beispiel: Ein Unternehmen kann Verkaufs-, Marketing- und Kundenservicedaten zusammenführen, um eine 360-Grad-Sicht auf seine Kunden zu erhalten.

2. Bessere Datenqualität und Konsistenz

- Daten aus unterschiedlichen Quellen können inkonsistent, redundant oder veraltet sein. Eine Zusammenführung ermöglicht es, Daten zu bereinigen, zu standardisieren und so eine einheitliche Datenbasis zu schaffen.
- Doppelte oder widersprüchliche Daten können identifiziert und bereinigt werden, was die Qualität und Zuverlässigkeit der Daten erhöht.

3. Effizienzsteigerung und Kosteneinsparung

- Die Pflege mehrerer, isolierter Datenquellen kann zeit- und ressourcenintensiv sein. Durch die Zusammenführung kann der Aufwand für Datenerfassung, -speicherung und -pflege reduziert werden.
- Eine zentrale Datenquelle erleichtert das Datenmanagement und reduziert redundante Speicherkosten.

4. Bessere Datenanalyse und -auswertung

- Wenn Daten zusammengeführt werden, können umfassendere und tiefere Analysen durchgeführt werden. Cross-Data-Analysen, die Informationen aus verschiedenen Quellen kombinieren, liefern oft wertvollere Erkenntnisse.
- Beispielsweise können durch die Verknüpfung von Verkaufsdaten und Web-Tracking-Daten Trends und Verhaltensmuster der Kunden besser verstanden werden.

5. Förderung von Innovationen

- Der Zugang zu umfassenden, vernetzten Datenquellen kann neue Erkenntnisse und Geschäftsmöglichkeiten aufdecken, die sonst verborgen bleiben würden.
- Unternehmen können neue Produkte, Dienstleistungen oder Geschäftsmodelle entwickeln, indem sie bestehende Daten besser nutzen und neue Zusammenhänge erkennen.

6. Bessere Entscheidungsfindung

- Mit integrierten Datenquellen kann das Management schneller und besser informierte Entscheidungen treffen, da sie auf einer vollständigen und aktuellen Datenbasis beruhen.
- Echtzeit-Zugriff auf alle relevanten Datenquellen fördert schnelle Reaktionen auf Marktveränderungen oder Kundenanforderungen.

7. Automatisierung und Prozessoptimierung

- Eine zusammengeführte Datenbasis erleichtert die Implementierung automatisierter Workflows und datengetriebener Prozesse, da benötigte Informationen zentral zugänglich sind.
- Beispielsweise können automatisierte Reports und Analysen generiert werden, ohne dass auf verschiedene Systeme zurückgegriffen werden muss.

8. Verbesserte Zusammenarbeit zwischen Abteilungen

- Eine zentrale Datenquelle unterstützt die Zusammenarbeit und den Informationsaustausch zwischen verschiedenen Abteilungen.
- Abteilungen wie Vertrieb, Marketing und Kundenservice haben oft ähnliche Datenanforderungen und profitieren von einer einheitlichen Datenbasis, um koordinierter zusammenzuarbeiten.

9. Compliance und Datensicherheit

- Zentralisierte Daten erleichtern es, Datenschutzbestimmungen und Compliance-Anforderungen zu erfüllen. Eine einheitliche Datenquelle ermöglicht eine bessere Kontrolle und Nachvollziehbarkeit der Datenzugriffe und -nutzung.
- Sicherheitsmaßnahmen und Datenschutzrichtlinien können effektiver umgesetzt werden, da weniger unterschiedliche Datenquellen gesichert und kontrolliert werden müssen.

10. Optimierte Kundenansprache und Personalisierung

- Durch die Zusammenführung von Kundendaten aus verschiedenen Kanälen (z. B. Social Media, Website, Kundensupport) kann eine personalisierte Ansprache ermöglicht werden.
- Unternehmen können gezieltere Marketingkampagnen durchführen und ihren Kunden eine individuelle User Experience bieten.

Insgesamt bietet die Zusammenführung von Datenquellen entscheidende Vorteile für Unternehmen, insbesondere in Bezug auf Datenqualität, Effizienz, Sicherheit und Erkenntnisgewinn.

---

##### Szenario: Analyse von Benutzeraktivitäten einer Webanwendung

Unternehmen:  
Ein Unternehmen bietet eine Webanwendung an, die von einer großen Anzahl an Nutzern verwendet wird. Die Anwendung verfolgt verschiedene Benutzeraktionen (z. B. Anmeldungen, Klicks, Käufe, Umsatz) und speichert sie in einem zentralen Server. Das Unternehmen möchte diese Daten regelmäßig exportieren, analysieren und in einem DataLake/Data Warehouse speichern, um das Nutzerverhalten besser zu verstehen und optimierte Marketingstrategien zu entwickeln. Regelmäßig sollen Berichte an Geschäftspartner mit Performancewerten versendet werden.

Auftrag:  
Das Unternehmen benötigt eine regelmäßige Datenübertragung von der Webanwendung in das/den DataLake/Data Warehouse. Da die Anwendung in Echtzeit läuft und Datenmengen relativ groß sind, müssen Dateiformate verwendet werden, die effizient übertragen, gelesen und werden können.

1. Informieren Sie sich in dieser Lernsequenz über das Zusammenführen von Datenquellen.
2. Entscheiden Sie für das Unternehmen, ob die Daten in einem Data Lake oder einem Data Warehouse abgelegt werden sollten. Begründen Sie!
3. Bilden Sie die für das Unternehmen relevanten Daten in die Formate JSON, XML und CSV ab.


### 1. Zusammenführen von Datenquellen
Beim Zusammenführen von Datenquellen ist es wichtig, Daten aus unterschiedlichen Systemen oder Formaten so zu integrieren, dass sie eine einheitliche Basis für Analysen bilden. Dabei gibt es zwei Hauptansätze:

- **ETL (Extract, Transform, Load)**: Daten werden aus Quellen extrahiert, transformiert (bereinigt, strukturiert, angereichert) und dann in ein Zielsystem geladen. Geeignet für strukturierte Daten, wie sie in einem Data Warehouse benötigt werden.
- **ELT (Extract, Load, Transform)**: Daten werden in roher Form in einen Data Lake geladen und anschließend transformiert. Geeignet für unstrukturierte oder semi-strukturierte Daten.

Wesentliche Schritte umfassen:
- **Extraktion** aus der Webanwendung (z. B. mittels APIs oder Datenbank-Dumps).
- **Transformation**, um Datenformate zu vereinheitlichen und die Qualität sicherzustellen.
- **Speicherung** der Daten in einem Data Lake oder Data Warehouse, abhängig von den Analyseanforderungen.

---

### 2. Entscheidung: Data Lake oder Data Warehouse?

#### **Data Lake**
- **Definition**: Ein zentrales Repository, in dem Rohdaten in ihrem ursprünglichen Format gespeichert werden, sei es strukturiert, semi-strukturiert oder unstrukturiert.
- **Vorteile**:
  - Flexibilität bei der Speicherung von großen Datenmengen aus verschiedenen Quellen (z. B. JSON, XML, CSV, Logs, Bilder).
  - Geeignet für Machine Learning und Big-Data-Analysen.
  - Geringere Speicherkosten im Vergleich zu einem Data Warehouse.
- **Nachteile**:
  - Höherer Aufwand für die Verarbeitung und Analyse der Daten, da Rohdaten unstrukturiert vorliegen.

#### **Data Warehouse**
- **Definition**: Eine relationale Datenbank, optimiert für komplexe Abfragen und Analysen von strukturierten Daten.
- **Vorteile**:
  - Bereitstellung strukturierter, konsistenter Daten für Berichte.
  - Geeignet für klassische BI-Tools und standardisierte Analysen.
  - Effiziente Abfragen bei voraggregierten Daten.
- **Nachteile**:
  - Höherer Aufwand für Datenmodellierung und Transformation.
  - Weniger flexibel bei der Verarbeitung von unstrukturierten Daten.

**Empfehlung**:  
Für das Unternehmen, das große Datenmengen in Echtzeit generiert und flexibel sowohl klassische Analysen als auch Machine Learning durchführen möchte, ist ein **hybrider Ansatz** sinnvoll:
1. **Data Lake** als primäres Repository für alle Rohdaten.
2. **Data Warehouse** für aggregierte und strukturierte Daten, die für Berichte benötigt werden.

---

### 3. Relevante Daten in JSON, XML und CSV abbilden

#### Beispiel-Datenstruktur:
| Aktion      | Benutzer-ID | Zeitstempel           | Wert      |
|-------------|-------------|-----------------------|-----------|
| Anmeldung   | 12345       | 2024-11-19T08:15:30Z |           |
| Klick       | 12345       | 2024-11-19T08:16:10Z | Produkt X |
| Kauf        | 12345       | 2024-11-19T08:18:05Z | 49.99     |

#### **JSON** (geeignet für semi-strukturierte Daten)
```json
[
    {
        "aktion": "Anmeldung",
        "benutzer_id": 12345,
        "zeitstempel": "2024-11-19T08:15:30Z"
    },
    {
        "aktion": "Klick",
        "benutzer_id": 12345,
        "zeitstempel": "2024-11-19T08:16:10Z",
        "wert": "Produkt X"
    },
    {
        "aktion": "Kauf",
        "benutzer_id": 12345,
        "zeitstempel": "2024-11-19T08:18:05Z",
        "wert": 49.99
    }
]
```

#### **XML** (geeignet für den Datenaustausch)
```xml
<aktionen>
    <aktion>
        <typ>Anmeldung</typ>
        <benutzer_id>12345</benutzer_id>
        <zeitstempel>2024-11-19T08:15:30Z</zeitstempel>
    </aktion>
    <aktion>
        <typ>Klick</typ>
        <benutzer_id>12345</benutzer_id>
        <zeitstempel>2024-11-19T08:16:10Z</zeitstempel>
        <wert>Produkt X</wert>
    </aktion>
    <aktion>
        <typ>Kauf</typ>
        <benutzer_id>12345</benutzer_id>
        <zeitstempel>2024-11-19T08:18:05Z</zeitstempel>
        <wert>49.99</wert>
    </aktion>
</aktionen>
```

#### **CSV** (geeignet für tabellarische Daten)
```csv
aktion,benutzer_id,zeitstempel,wert
Anmeldung,12345,2024-11-19T08:15:30Z,
Klick,12345,2024-11-19T08:16:10Z,Produkt X
Kauf,12345,2024-11-19T08:18:05Z,49.99
```

---

### Fazit
- **Datenformate**: JSON für Flexibilität, XML für den Austausch, CSV für Berichte.
- **Speicherort**: Kombination aus Data Lake und Data Warehouse für maximale Flexibilität und Effizienz.
- **Nächste Schritte**:
  - Implementierung einer Datenpipeline für den regelmäßigen Transfer in den Data Lake.
  - Aufbau eines Data Warehouses für aggregierte Auswertungen und Berichte.

[[JSON, XML, csv]]